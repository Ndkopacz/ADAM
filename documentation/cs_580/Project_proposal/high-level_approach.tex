\section{High-level Approach}
\begin{itemize}
    \item Data: In order to train the ADAM model for the particular task of threat detection, we will first use ImageNet to pre-train the model.
        The fine tuning of the model for the specific task will be done on an origial dataset that we will collect. 
        The dataset will contain images captured from the Raspberry Pi itself to ensure that the model can generalize well to real-world data. 
        Since the system will operate in a real-time environment, it is essential that the dataset be representative of various lighting conditions, angles, and distances. 
        Because the data is staged, it will be annotated as containing a threat or not. The threats will be various and possibly creative.
    \item Model Training: The machine learning model will be trained using transfer learning on a pre-trained model like YOLO or Inception. 
        Transfer learning enables us to leverage a model that has already learned to detect a wide range of objects and adapt it to threat-detection. 
        This approach allows us to significantly reduce the time and computational resources needed for training. 
        The model will be optimized to run efficiently on the Raspberry Pi. 
        Additionally, we will ensure that the model only triggers the deterrent when a  is detected in 3 out of 5 consecutive frames, minimizing false positives and ensuring reliability in real-world use.
    \item Model Analysis (Input Interpretability using LIME): Once the model is trained, it is important to understand how the model arrives at its decisions. 
        For this, we will focus on input interpretability, using LIME. 
        LIME is a technique that explains how individual predictions are made by perturbing the input data and observing how the predictions change. 
        It provides an intuitive understanding of which parts of an image the model focuses on when making its decision. 
        With the combine broad classification over ImageNet and fine-tuning, it is expected that the model will learn to associate certain objects in a scene with a threat. As an example, a gun may be a threat, but not when it is in the hands of a police officer.
        We will run LIME analyses on a range of test images to assess how well the model is interpreting the inputs and to identify any potential weaknesses in its decision-making process.
    \item In addition to ensuring that the model is accurate, we must also verify that it is robust to perturbation. 
    In real-world environments, the quality of the input data may vary due to factors such as low lighting, camera noise. 
    Robustness testing will involve intentionally introducing noise or distortions into the test images and evaluating the modelâ€™s ability to maintain accuracy. 
    For example, we may test how the model performs when the image is blurred, or when the lighting is uneven. 
    Beyond just testing, we will explore training techniques that improve robustness, such as data augmentation. 
\end{itemize}
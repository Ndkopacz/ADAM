{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolo\n",
    "\n",
    "Below are two ways of loading Yolo.\n",
    "I initially thought that in order to adjust the pretrained model I would need the `.yaml` but this ended up not working.\n",
    "Both of these are almost equivalent, but after some testing, if the load that doesn't require the files works without a problem, I'll just use that and remove the extra files.\n",
    "\n",
    "### Manual install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's skip this part. Remote load ftw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1    615133  yolo.Segment                            [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], 32, 128, [128, 256, 512]]\n",
      "YOLOv5s-seg summary: 225 layers, 7621277 parameters, 7621277 gradients, 26.6 GFLOPs\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from yolo import Model\n",
    "\n",
    "config_path = '../yolov5s-seg.yaml'\n",
    "weights_path = '../yolov5s-seg.pt'\n",
    "\n",
    "model = Model(config_path)\n",
    "\n",
    "checkpoint = torch.load(weights_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'].state_dict(), strict=False)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remote load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/august/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-11-8 Python-3.12.2 torch-2.5.1+cu124 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5n6 summary: 280 layers, 3239884 parameters, 0 gradients, 4.6 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoShape(\n",
      "  (model): DetectMultiBackend(\n",
      "    (model): DetectionModel(\n",
      "      (model): Sequential(\n",
      "        (0): Conv(\n",
      "          (conv): Conv2d(3, 16, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv(\n",
      "          (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (2): C3(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv3): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): Conv(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (4): C3(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv3): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (1): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): Conv(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (6): C3(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv3): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (1): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "            (2): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (7): Conv(\n",
      "          (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (8): C3(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv3): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (9): Conv(\n",
      "          (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (10): C3(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv3): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (11): SPPF(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (12): Conv(\n",
      "          (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (13): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (14): Concat()\n",
      "        (15): C3(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv3): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (16): Conv(\n",
      "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (17): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (18): Concat()\n",
      "        (19): C3(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv3): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (20): Conv(\n",
      "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (21): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (22): Concat()\n",
      "        (23): C3(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv3): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (24): Conv(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (25): Concat()\n",
      "        (26): C3(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv3): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (27): Conv(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (28): Concat()\n",
      "        (29): C3(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv3): Conv(\n",
      "            (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (30): Conv(\n",
      "          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (31): Concat()\n",
      "        (32): C3(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv3): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (m): Sequential(\n",
      "            (0): Bottleneck(\n",
      "              (cv1): Conv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "              (cv2): Conv(\n",
      "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (act): SiLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (33): Detect(\n",
      "          (m): ModuleList(\n",
      "            (0): Conv2d(64, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): Conv2d(128, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (2): Conv2d(192, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (3): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5n6', pretrained=True)\n",
    "#model = model.model.model\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/august/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:865: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[3.87914e+00, 4.61340e+00, 1.53272e+01, 2.59218e+01, 4.25550e-01, 4.49479e-01],\n",
       "         [1.16913e+01, 4.77067e+00, 1.39160e+01, 2.50988e+01, 4.42472e-01, 4.55111e-01],\n",
       "         [1.94664e+01, 4.79392e+00, 1.41533e+01, 2.40440e+01, 4.37330e-01, 4.70713e-01],\n",
       "         ...,\n",
       "         [1.11402e+03, 1.23742e+03, 8.32489e+02, 6.82587e+02, 4.60790e-01, 5.35804e-01],\n",
       "         [1.17759e+03, 1.23762e+03, 8.69414e+02, 7.13116e+02, 4.48060e-01, 5.40008e-01],\n",
       "         [1.24056e+03, 1.24039e+03, 8.45446e+02, 6.70228e+02, 4.39121e-01, 5.44429e-01]]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel = 1280\n",
    "image = torch.rand(1, 3, pixel, pixel)\n",
    "model(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple way to look at the keys of the model weights\n",
    "The weights themselves can be accessed by `model.state_dict()[key]`\n",
    "\n",
    "These are groups of parameters, and they are numbered by layer.\n",
    "We can use these to identify which parameters to freeze during fine tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.0.conv.weight\n",
      "model.0.conv.bias\n",
      "model.1.conv.weight\n",
      "model.1.conv.bias\n",
      "model.2.cv1.conv.weight\n",
      "model.2.cv1.conv.bias\n",
      "model.2.cv2.conv.weight\n",
      "model.2.cv2.conv.bias\n",
      "model.2.cv3.conv.weight\n",
      "model.2.cv3.conv.bias\n",
      "model.2.m.0.cv1.conv.weight\n",
      "model.2.m.0.cv1.conv.bias\n",
      "model.2.m.0.cv2.conv.weight\n",
      "model.2.m.0.cv2.conv.bias\n",
      "model.3.conv.weight\n",
      "model.3.conv.bias\n",
      "model.4.cv1.conv.weight\n",
      "model.4.cv1.conv.bias\n",
      "model.4.cv2.conv.weight\n",
      "model.4.cv2.conv.bias\n",
      "model.4.cv3.conv.weight\n",
      "model.4.cv3.conv.bias\n",
      "model.4.m.0.cv1.conv.weight\n",
      "model.4.m.0.cv1.conv.bias\n",
      "model.4.m.0.cv2.conv.weight\n",
      "model.4.m.0.cv2.conv.bias\n",
      "model.4.m.1.cv1.conv.weight\n",
      "model.4.m.1.cv1.conv.bias\n",
      "model.4.m.1.cv2.conv.weight\n",
      "model.4.m.1.cv2.conv.bias\n",
      "model.5.conv.weight\n",
      "model.5.conv.bias\n",
      "model.6.cv1.conv.weight\n",
      "model.6.cv1.conv.bias\n",
      "model.6.cv2.conv.weight\n",
      "model.6.cv2.conv.bias\n",
      "model.6.cv3.conv.weight\n",
      "model.6.cv3.conv.bias\n",
      "model.6.m.0.cv1.conv.weight\n",
      "model.6.m.0.cv1.conv.bias\n",
      "model.6.m.0.cv2.conv.weight\n",
      "model.6.m.0.cv2.conv.bias\n",
      "model.6.m.1.cv1.conv.weight\n",
      "model.6.m.1.cv1.conv.bias\n",
      "model.6.m.1.cv2.conv.weight\n",
      "model.6.m.1.cv2.conv.bias\n",
      "model.6.m.2.cv1.conv.weight\n",
      "model.6.m.2.cv1.conv.bias\n",
      "model.6.m.2.cv2.conv.weight\n",
      "model.6.m.2.cv2.conv.bias\n",
      "model.7.conv.weight\n",
      "model.7.conv.bias\n",
      "model.8.cv1.conv.weight\n",
      "model.8.cv1.conv.bias\n",
      "model.8.cv2.conv.weight\n",
      "model.8.cv2.conv.bias\n",
      "model.8.cv3.conv.weight\n",
      "model.8.cv3.conv.bias\n",
      "model.8.m.0.cv1.conv.weight\n",
      "model.8.m.0.cv1.conv.bias\n",
      "model.8.m.0.cv2.conv.weight\n",
      "model.8.m.0.cv2.conv.bias\n",
      "model.9.conv.weight\n",
      "model.9.conv.bias\n",
      "model.10.cv1.conv.weight\n",
      "model.10.cv1.conv.bias\n",
      "model.10.cv2.conv.weight\n",
      "model.10.cv2.conv.bias\n",
      "model.10.cv3.conv.weight\n",
      "model.10.cv3.conv.bias\n",
      "model.10.m.0.cv1.conv.weight\n",
      "model.10.m.0.cv1.conv.bias\n",
      "model.10.m.0.cv2.conv.weight\n",
      "model.10.m.0.cv2.conv.bias\n",
      "model.11.cv1.conv.weight\n",
      "model.11.cv1.conv.bias\n",
      "model.11.cv2.conv.weight\n",
      "model.11.cv2.conv.bias\n",
      "model.12.conv.weight\n",
      "model.12.conv.bias\n",
      "model.15.cv1.conv.weight\n",
      "model.15.cv1.conv.bias\n",
      "model.15.cv2.conv.weight\n",
      "model.15.cv2.conv.bias\n",
      "model.15.cv3.conv.weight\n",
      "model.15.cv3.conv.bias\n",
      "model.15.m.0.cv1.conv.weight\n",
      "model.15.m.0.cv1.conv.bias\n",
      "model.15.m.0.cv2.conv.weight\n",
      "model.15.m.0.cv2.conv.bias\n",
      "model.16.conv.weight\n",
      "model.16.conv.bias\n",
      "model.19.cv1.conv.weight\n",
      "model.19.cv1.conv.bias\n",
      "model.19.cv2.conv.weight\n",
      "model.19.cv2.conv.bias\n",
      "model.19.cv3.conv.weight\n",
      "model.19.cv3.conv.bias\n",
      "model.19.m.0.cv1.conv.weight\n",
      "model.19.m.0.cv1.conv.bias\n",
      "model.19.m.0.cv2.conv.weight\n",
      "model.19.m.0.cv2.conv.bias\n",
      "model.20.conv.weight\n",
      "model.20.conv.bias\n",
      "model.23.cv1.conv.weight\n",
      "model.23.cv1.conv.bias\n",
      "model.23.cv2.conv.weight\n",
      "model.23.cv2.conv.bias\n",
      "model.23.cv3.conv.weight\n",
      "model.23.cv3.conv.bias\n",
      "model.23.m.0.cv1.conv.weight\n",
      "model.23.m.0.cv1.conv.bias\n",
      "model.23.m.0.cv2.conv.weight\n",
      "model.23.m.0.cv2.conv.bias\n",
      "model.24.conv.weight\n",
      "model.24.conv.bias\n",
      "model.26.cv1.conv.weight\n",
      "model.26.cv1.conv.bias\n",
      "model.26.cv2.conv.weight\n",
      "model.26.cv2.conv.bias\n",
      "model.26.cv3.conv.weight\n",
      "model.26.cv3.conv.bias\n",
      "model.26.m.0.cv1.conv.weight\n",
      "model.26.m.0.cv1.conv.bias\n",
      "model.26.m.0.cv2.conv.weight\n",
      "model.26.m.0.cv2.conv.bias\n",
      "model.27.conv.weight\n",
      "model.27.conv.bias\n",
      "model.29.cv1.conv.weight\n",
      "model.29.cv1.conv.bias\n",
      "model.29.cv2.conv.weight\n",
      "model.29.cv2.conv.bias\n",
      "model.29.cv3.conv.weight\n",
      "model.29.cv3.conv.bias\n",
      "model.29.m.0.cv1.conv.weight\n",
      "model.29.m.0.cv1.conv.bias\n",
      "model.29.m.0.cv2.conv.weight\n",
      "model.29.m.0.cv2.conv.bias\n",
      "model.30.conv.weight\n",
      "model.30.conv.bias\n",
      "model.32.cv1.conv.weight\n",
      "model.32.cv1.conv.bias\n",
      "model.32.cv2.conv.weight\n",
      "model.32.cv2.conv.bias\n",
      "model.32.cv3.conv.weight\n",
      "model.32.cv3.conv.bias\n",
      "model.32.m.0.cv1.conv.weight\n",
      "model.32.m.0.cv1.conv.bias\n",
      "model.32.m.0.cv2.conv.weight\n",
      "model.32.m.0.cv2.conv.bias\n",
      "model.33.anchors\n",
      "model.33.m.0.weight\n",
      "model.33.m.0.bias\n",
      "model.33.m.1.weight\n",
      "model.33.m.1.bias\n",
      "model.33.m.2.weight\n",
      "model.33.m.2.bias\n",
      "model.33.m.3.weight\n",
      "model.33.m.3.bias\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weights = model.state_dict()\n",
    "for key in weights:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapting the model\n",
    "\n",
    "Below I will adapt the model for threat detection.\n",
    "The original pretrained model predicts 80 classes.\n",
    "We are interested in binary classification, so the final layer will be a scalar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "sub_model = model.model.model\n",
    "num_anchors = sub_model.model[-1].na  \n",
    "sub_model.model[-1].nc = 1 # Number of outputs for binary classification\n",
    "num_anchors = 1\n",
    "sub_model.model[-1].no = num_anchors * (sub_model.model[-1].nc + 5)  \n",
    "\n",
    "for i, conv in enumerate(sub_model.model[-1].m):\n",
    "    in_channels = conv.in_channels\n",
    "    out_channels = sub_model.model[-1].no * sub_model.model[-1].na  \n",
    "\n",
    "    sub_model.model[-1].m[i] = nn.Conv2d(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=conv.kernel_size,\n",
    "        stride=conv.stride,\n",
    "        padding=conv.padding\n",
    "    )\n",
    "\n",
    "    torch.nn.init.normal_(sub_model.model[-1].m[i].weight, mean=0.0, std=0.01)\n",
    "    torch.nn.init.constant_(sub_model.model[-1].m[i].bias, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we test it out with a random image.\n",
    "You will note that there the output is a 3D tensor.\n",
    "Now the first dimension of course is just the batch, but why the $102000 \\times 6$ matrix, when we wanted a scalar.\n",
    "Well the answer is that Yolo breaks the image space into grids and makes a prediction about each grid location.\n",
    "There are $102000$ predictions being made.\n",
    "The $6$ is how it makes its prediction and scores\n",
    "\n",
    "* x,y,w,h of the bounding box\n",
    "* objectness: confidence that some object exists in the box\n",
    "* confidence: The confidence that the object is in the class (threat)\n",
    "\n",
    "There is an additional issue of this tensor taking a different form in training mode.\n",
    "We want to keep it in training mode when we train so it doesn't mess up the internals of yolo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/august/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:865: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/home/august/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:865: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape = torch.Size([2, 102000, 6])\n",
      "output = tensor([[[2.90932e+00, 3.60545e+00, 1.40544e+01, 3.60025e+01, 5.02639e-01, 4.97406e-01],\n",
      "         [1.10023e+01, 3.32069e+00, 1.44107e+01, 3.68102e+01, 4.86166e-01, 4.84209e-01],\n",
      "         [1.89556e+01, 3.49945e+00, 1.51711e+01, 3.71174e+01, 4.65884e-01, 5.05324e-01],\n",
      "         ...,\n",
      "         [1.12293e+03, 1.24942e+03, 8.85134e+02, 9.37457e+02, 5.64633e-01, 5.08909e-01],\n",
      "         [1.18651e+03, 1.24861e+03, 9.10876e+02, 9.21034e+02, 5.57338e-01, 5.08853e-01],\n",
      "         [1.24867e+03, 1.24693e+03, 9.77977e+02, 9.18000e+02, 5.51443e-01, 5.16241e-01]],\n",
      "\n",
      "        [[3.18700e+00, 3.48772e+00, 1.55447e+01, 3.67212e+01, 4.81376e-01, 5.09311e-01],\n",
      "         [1.12526e+01, 3.25687e+00, 1.58933e+01, 3.67263e+01, 4.79241e-01, 4.97551e-01],\n",
      "         [1.93645e+01, 3.40585e+00, 1.62613e+01, 3.70259e+01, 4.84051e-01, 5.03946e-01],\n",
      "         ...,\n",
      "         [1.12291e+03, 1.24875e+03, 8.94678e+02, 9.26008e+02, 5.61515e-01, 5.08145e-01],\n",
      "         [1.18605e+03, 1.24805e+03, 9.29659e+02, 9.20309e+02, 5.56255e-01, 5.08139e-01],\n",
      "         [1.24819e+03, 1.24648e+03, 9.78049e+02, 9.23466e+02, 5.55124e-01, 5.19792e-01]]])\n",
      "shape = torch.Size([2, 3, 160, 160, 6])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = model(image)\n",
    "print(f'shape = {out.shape}')\n",
    "print(f'output = {out}')\n",
    "\n",
    "model.train()\n",
    "out = model(image)\n",
    "print(f'shape = {out[0].shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.0.conv.weight\n",
      "model.0.conv.bias\n",
      "model.1.conv.weight\n",
      "model.1.conv.bias\n",
      "model.2.cv1.conv.weight\n",
      "model.2.cv1.conv.bias\n",
      "model.2.cv2.conv.weight\n",
      "model.2.cv2.conv.bias\n",
      "model.2.cv3.conv.weight\n",
      "model.2.cv3.conv.bias\n",
      "model.2.m.0.cv1.conv.weight\n",
      "model.2.m.0.cv1.conv.bias\n",
      "model.2.m.0.cv2.conv.weight\n",
      "model.2.m.0.cv2.conv.bias\n",
      "model.3.conv.weight\n",
      "model.3.conv.bias\n",
      "model.4.cv1.conv.weight\n",
      "model.4.cv1.conv.bias\n",
      "model.4.cv2.conv.weight\n",
      "model.4.cv2.conv.bias\n",
      "model.4.cv3.conv.weight\n",
      "model.4.cv3.conv.bias\n",
      "model.4.m.0.cv1.conv.weight\n",
      "model.4.m.0.cv1.conv.bias\n",
      "model.4.m.0.cv2.conv.weight\n",
      "model.4.m.0.cv2.conv.bias\n",
      "model.4.m.1.cv1.conv.weight\n",
      "model.4.m.1.cv1.conv.bias\n",
      "model.4.m.1.cv2.conv.weight\n",
      "model.4.m.1.cv2.conv.bias\n",
      "model.5.conv.weight\n",
      "model.5.conv.bias\n",
      "model.6.cv1.conv.weight\n",
      "model.6.cv1.conv.bias\n",
      "model.6.cv2.conv.weight\n",
      "model.6.cv2.conv.bias\n",
      "model.6.cv3.conv.weight\n",
      "model.6.cv3.conv.bias\n",
      "model.6.m.0.cv1.conv.weight\n",
      "model.6.m.0.cv1.conv.bias\n",
      "model.6.m.0.cv2.conv.weight\n",
      "model.6.m.0.cv2.conv.bias\n",
      "model.6.m.1.cv1.conv.weight\n",
      "model.6.m.1.cv1.conv.bias\n",
      "model.6.m.1.cv2.conv.weight\n",
      "model.6.m.1.cv2.conv.bias\n",
      "model.6.m.2.cv1.conv.weight\n",
      "model.6.m.2.cv1.conv.bias\n",
      "model.6.m.2.cv2.conv.weight\n",
      "model.6.m.2.cv2.conv.bias\n",
      "model.7.conv.weight\n",
      "model.7.conv.bias\n",
      "model.8.cv1.conv.weight\n",
      "model.8.cv1.conv.bias\n",
      "model.8.cv2.conv.weight\n",
      "model.8.cv2.conv.bias\n",
      "model.8.cv3.conv.weight\n",
      "model.8.cv3.conv.bias\n",
      "model.8.m.0.cv1.conv.weight\n",
      "model.8.m.0.cv1.conv.bias\n",
      "model.8.m.0.cv2.conv.weight\n",
      "model.8.m.0.cv2.conv.bias\n",
      "model.9.conv.weight\n",
      "model.9.conv.bias\n",
      "model.10.cv1.conv.weight\n",
      "model.10.cv1.conv.bias\n",
      "model.10.cv2.conv.weight\n",
      "model.10.cv2.conv.bias\n",
      "model.10.cv3.conv.weight\n",
      "model.10.cv3.conv.bias\n",
      "model.10.m.0.cv1.conv.weight\n",
      "model.10.m.0.cv1.conv.bias\n",
      "model.10.m.0.cv2.conv.weight\n",
      "model.10.m.0.cv2.conv.bias\n",
      "model.11.cv1.conv.weight\n",
      "model.11.cv1.conv.bias\n",
      "model.11.cv2.conv.weight\n",
      "model.11.cv2.conv.bias\n",
      "model.12.conv.weight\n",
      "model.12.conv.bias\n",
      "model.15.cv1.conv.weight\n",
      "model.15.cv1.conv.bias\n",
      "model.15.cv2.conv.weight\n",
      "model.15.cv2.conv.bias\n",
      "model.15.cv3.conv.weight\n",
      "model.15.cv3.conv.bias\n",
      "model.15.m.0.cv1.conv.weight\n",
      "model.15.m.0.cv1.conv.bias\n",
      "model.15.m.0.cv2.conv.weight\n",
      "model.15.m.0.cv2.conv.bias\n",
      "model.16.conv.weight\n",
      "model.16.conv.bias\n",
      "model.19.cv1.conv.weight\n",
      "model.19.cv1.conv.bias\n",
      "model.19.cv2.conv.weight\n",
      "model.19.cv2.conv.bias\n",
      "model.19.cv3.conv.weight\n",
      "model.19.cv3.conv.bias\n",
      "model.19.m.0.cv1.conv.weight\n",
      "model.19.m.0.cv1.conv.bias\n",
      "model.19.m.0.cv2.conv.weight\n",
      "model.19.m.0.cv2.conv.bias\n",
      "model.20.conv.weight\n",
      "model.20.conv.bias\n",
      "model.23.cv1.conv.weight\n",
      "model.23.cv1.conv.bias\n",
      "model.23.cv2.conv.weight\n",
      "model.23.cv2.conv.bias\n",
      "model.23.cv3.conv.weight\n",
      "model.23.cv3.conv.bias\n",
      "model.23.m.0.cv1.conv.weight\n",
      "model.23.m.0.cv1.conv.bias\n",
      "model.23.m.0.cv2.conv.weight\n",
      "model.23.m.0.cv2.conv.bias\n",
      "model.24.conv.weight\n",
      "model.24.conv.bias\n",
      "model.26.cv1.conv.weight\n",
      "model.26.cv1.conv.bias\n",
      "model.26.cv2.conv.weight\n",
      "model.26.cv2.conv.bias\n",
      "model.26.cv3.conv.weight\n",
      "model.26.cv3.conv.bias\n",
      "model.26.m.0.cv1.conv.weight\n",
      "model.26.m.0.cv1.conv.bias\n",
      "model.26.m.0.cv2.conv.weight\n",
      "model.26.m.0.cv2.conv.bias\n",
      "model.27.conv.weight\n",
      "model.27.conv.bias\n",
      "model.29.cv1.conv.weight\n",
      "model.29.cv1.conv.bias\n",
      "model.29.cv2.conv.weight\n",
      "model.29.cv2.conv.bias\n",
      "model.29.cv3.conv.weight\n",
      "model.29.cv3.conv.bias\n",
      "model.29.m.0.cv1.conv.weight\n",
      "model.29.m.0.cv1.conv.bias\n",
      "model.29.m.0.cv2.conv.weight\n",
      "model.29.m.0.cv2.conv.bias\n",
      "model.30.conv.weight\n",
      "model.30.conv.bias\n",
      "model.32.cv1.conv.weight\n",
      "model.32.cv1.conv.bias\n",
      "model.32.cv2.conv.weight\n",
      "model.32.cv2.conv.bias\n",
      "model.32.cv3.conv.weight\n",
      "model.32.cv3.conv.bias\n",
      "model.32.m.0.cv1.conv.weight\n",
      "model.32.m.0.cv1.conv.bias\n",
      "model.32.m.0.cv2.conv.weight\n",
      "model.32.m.0.cv2.conv.bias\n",
      "model.33.anchors\n",
      "model.33.m.0.weight\n",
      "model.33.m.0.bias\n",
      "model.33.m.1.weight\n",
      "model.33.m.1.bias\n",
      "model.33.m.2.weight\n",
      "model.33.m.2.bias\n",
      "model.33.m.3.weight\n",
      "model.33.m.3.bias\n"
     ]
    }
   ],
   "source": [
    "weights = model.state_dict()\n",
    "for key in weights:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DetectionModel(\n",
       "  (model): Sequential(\n",
       "    (0): Conv(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Conv(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Conv(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (4): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): Conv(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (6): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): Conv(\n",
       "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (8): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): SPPF(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (10): Conv(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (11): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (12): Concat()\n",
       "    (13): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): Conv(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (15): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (16): Concat()\n",
       "    (17): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (18): Conv(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (19): Concat()\n",
       "    (20): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (21): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (22): Concat()\n",
       "    (23): C3(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (24): Detect(\n",
       "      (m): ModuleList(\n",
       "        (0): Conv2d(128, 54, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(256, 54, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(512, 54, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.state_dict()\n",
    "for key in weights:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as discussed this setup is not quite what we want.\n",
    "Here how I plan to resolve this.\n",
    "First, I will extract the prediction vectors for the objectness and class confidences.\n",
    "These will be lineary projected onto a scalar value and the resulting logit will be converted to a probability through sigmoid.\n",
    "The linear layer will of course be trainable.\n",
    "This will effectively give us a single scalar value probability, which we can calculate cross entropy loss against our human labeled data.\n",
    "\n",
    "I **could** demonstrate this in a few cells below, but I'm going to cut to the chase here.\n",
    "\n",
    "Below I will define a class `YoloThreat` which encapsulates all of the functionality we need, and simply demonstrate that it works after.\n",
    "Additionally, I'll make getting a freshly mutilated pretrained model easy, so we can declaritively pretrain these guys quickly.\n",
    "\n",
    "The final important consideration is the downscaling.\n",
    "1080p is $1920 \\times 1080$ pixels.\n",
    "For this we can use pytorch's interpolate function.\n",
    "The thing is we don't want to do this during training because of added compute, but it is necessary functionality at inference.\n",
    "We can simply preprocess our training, testing, and validation data to conform to the input size.\n",
    "When deployed, the data is live so this needs to be built into the model.\n",
    "\n",
    "In order to fix the training mode tensor shape issue, I adapted some code from the yolo source code.\n",
    "\n",
    "I'll also make it so we can freeze layers at will for finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from yolo import Segment\n",
    "\n",
    "class YoloThreat(nn.Module):\n",
    "    pixel = 1280\n",
    "    base_model = 'yolov5n6'\n",
    "\n",
    "    def __init__(self, yolo_model):\n",
    "        super(YoloThreat, self).__init__()\n",
    "        self.yolo = yolo_model\n",
    "        self.yolo_pred_count = 102000\n",
    "        self.fc = nn.Linear(self.yolo_pred_count * 2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Just incase the input is not batched, we add a batch dimension\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(0)\n",
    "        # In evaluation mode, we rescale the input\n",
    "        if not self.training:\n",
    "            batch_size, _, _, _ = x.shape\n",
    "            x = F.interpolate(x, size=(self.pixel, self.pixel), mode='bilinear', align_corners=False)\n",
    "\n",
    "        yolo_out = self.yolo(x)\n",
    "        if self.training:\n",
    "            yolo_out = self.collect(yolo_out)\n",
    "        else:\n",
    "            yolo_out = yolo_out[-1]\n",
    "\n",
    "        objectness = yolo_out[:, :, 4]\n",
    "        class_probs = yolo_out[:, :, 5]\n",
    "        yolo_out = torch.cat((objectness, class_probs), dim=-1)\n",
    "        yolo_out = yolo_out.view(-1, self.yolo_pred_count * 2)\n",
    "\n",
    "        logit = self.fc(yolo_out)\n",
    "        return self.sigmoid(logit)\n",
    "    \n",
    "    # Adapted from Yolo source code. This reshapes the output tensor so we get the same shape in training and evaluation\n",
    "    def collect(self, x):\n",
    "        yolo = self.yolo.model[-1]  # Detect()\n",
    "        z = []\n",
    "        for i in range(yolo.nl):\n",
    "            bs, _, ny, nx, _ = x[i].shape\n",
    "            y = x[i].view(bs, yolo.na, yolo.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()\n",
    "\n",
    "            if yolo.dynamic or yolo.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
    "                        yolo.grid[i], yolo.anchor_grid[i] = yolo._make_grid(nx, ny, i)\n",
    "\n",
    "            if isinstance(yolo, Segment):  # (boxes + masks)\n",
    "                xy, wh, conf, mask = x[i].split((2, 2, yolo.nc + 1, yolo.no - yolo.nc - 5), 4)\n",
    "                xy = (xy.sigmoid() * 2 + yolo.grid[i]) * yolo.stride[i]  # xy\n",
    "                wh = (wh.sigmoid() * 2) ** 2 * yolo.anchor_grid[i]  # wh\n",
    "                y = torch.cat((xy, wh, conf.sigmoid(), mask), 4)\n",
    "            else:  # Detect (boxes only)\n",
    "                xy, wh, conf = x[i].sigmoid().split((2, 2, yolo.nc + 1), 4)\n",
    "                xy = (xy * 2 + yolo.grid[i]) * yolo.stride[i]  # xy\n",
    "                wh = (wh * 2) ** 2 * yolo.anchor_grid[i]  # wh\n",
    "                y = torch.cat((xy, wh, conf), 4)\n",
    "            z.append(y.view(bs, yolo.na * nx * ny, yolo.no))\n",
    "\n",
    "        return torch.cat(z, 1)\n",
    "    \n",
    "    '''\n",
    "    Freeze all yolo layers below the specified layer number, and unfreeze the rest\n",
    "    Enter 0 to unfreeze all layers\n",
    "    '''\n",
    "    def freeze_below(self, layer):\n",
    "         if layer < 0 or layer > 34:\n",
    "            raise ValueError('Layer number must be between 0 and 34')\n",
    "\n",
    "         for name, param in self.yolo.named_parameters():\n",
    "            name = name.split('.')\n",
    "            if name[0] == 'yolo':\n",
    "                if int(name[2]) < layer:\n",
    "                    param.requires_grad = False\n",
    "                    continue\n",
    "            param.requires_grad = True\n",
    "\n",
    "    @staticmethod\n",
    "    def load_new_model():\n",
    "        yolo_model = torch.hub.load('ultralytics/yolov5', YoloThreat.base_model, pretrained=True)\n",
    "        yolo_model = yolo_model.model.model\n",
    "\n",
    "        num_anchors = yolo_model.model[-1].na  \n",
    "        yolo_model.model[-1].nc = 1 # Number of outputs for binary classification\n",
    "        num_anchors = 1\n",
    "        yolo_model.model[-1].no = num_anchors * (yolo_model.model[-1].nc + 5)  \n",
    "\n",
    "        for i, conv in enumerate(yolo_model.model[-1].m):\n",
    "            in_channels = conv.in_channels\n",
    "            out_channels = yolo_model.model[-1].no * yolo_model.model[-1].na  \n",
    "\n",
    "            yolo_model.model[-1].m[i] = nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=conv.kernel_size,\n",
    "                stride=conv.stride,\n",
    "                padding=conv.padding\n",
    "            )\n",
    "\n",
    "            torch.nn.init.normal_(yolo_model.model[-1].m[i].weight, mean=0.0, std=0.01)\n",
    "            torch.nn.init.constant_(yolo_model.model[-1].m[i].bias, 0.0)\n",
    "\n",
    "        return YoloThreat(yolo_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for a couple tests.\n",
    "First when the pixels are the right size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel = 1280\n",
    "image = torch.rand(2, 3, pixel, pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape = torch.Size([2, 3, 1280, 1280])\n",
      "tensor([[0.55576],\n",
      "        [0.55440]], grad_fn=<SigmoidBackward0>)\n",
      "x shape = torch.Size([2, 3, 1280, 1280])\n",
      "tensor([[0.55576],\n",
      "        [0.55440]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = YoloThreat.load_new_model()\n",
    "model.train()\n",
    "out = model(image)\n",
    "print(out)\n",
    "model.eval()\n",
    "out = model(image)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And when they need to be downsized (only in eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape = torch.Size([2, 3, 1280, 1280])\n",
      "tensor([[0.55731],\n",
      "        [0.55573]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "image = torch.rand(2, 3, 1920, 1080)\n",
    "model.eval()\n",
    "out = model(image)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
